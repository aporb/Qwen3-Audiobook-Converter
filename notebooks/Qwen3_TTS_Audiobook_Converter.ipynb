{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3-TTS Audiobook Converter\n",
    "\n",
    "**Main Use Case:** Upload an EPUB + voice sample → Get a voice-cloned audiobook\n",
    "\n",
    "**Supported Environments:**\n",
    "- Google Colab (with GPU - recommended)\n",
    "- VS Code with Jupyter extension\n",
    "- Standard Jupyter notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## Important: Enable GPU Runtime (Colab)\n",
    "\n",
    "If using Google Colab:\n",
    "1. Go to **Runtime** > **Change runtime type**\n",
    "2. Select **T4 GPU** (or A100 if available)\n",
    "3. Click **Save**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Environment: Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Environment: Local Jupyter (VS Code or standalone)\")\n",
    "\n",
    "# Install dependencies\n",
    "print(\"\\nInstalling dependencies...\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q qwen-tts>=0.0.5 openai-whisper soundfile ebooklib PyPDF2 pydub beautifulsoup4\n",
    "else:\n",
    "    %pip install -q qwen-tts>=0.0.5 openai-whisper soundfile ebooklib PyPDF2 pydub beautifulsoup4 ipywidgets\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core imports\nimport os\nimport re\nimport zipfile\nimport time\nimport subprocess\nimport xml.etree.ElementTree as ET\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple, Dict\nfrom dataclasses import dataclass\nfrom html import unescape\n\nimport numpy as np\nimport torch\nimport soundfile as sf\nimport whisper\nfrom qwen_tts import Qwen3TTSModel\nfrom tqdm.auto import tqdm\nfrom IPython.display import Audio, display, HTML, clear_output\n\n# Book processing\nimport PyPDF2\nfrom pydub import AudioSegment\n\ntry:\n    from bs4 import BeautifulSoup\n    BS4_AVAILABLE = True\nexcept ImportError:\n    BS4_AVAILABLE = False\n\n# Environment-specific imports\nif IN_COLAB:\n    from google.colab import files\n    WIDGETS_AVAILABLE = False\nelse:\n    try:\n        import ipywidgets as widgets\n        from IPython.display import display\n        WIDGETS_AVAILABLE = True\n    except ImportError:\n        WIDGETS_AVAILABLE = False\n\nprint(\"All imports successful!\")\nif not IN_COLAB:\n    print(f\"File picker widgets: {'Available' if WIDGETS_AVAILABLE else 'Not available (using text input)'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device detection\n",
    "def get_device_and_dtype():\n",
    "    \"\"\"Auto-detect the best available device and appropriate dtype.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        dtype = torch.bfloat16\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        dtype = torch.float32\n",
    "        print(\"Device: Apple Silicon (MPS)\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        dtype = torch.float32\n",
    "        print(\"Device: CPU (this will be slow)\")\n",
    "    return device, dtype\n",
    "\n",
    "DEVICE, DTYPE = get_device_and_dtype()\n",
    "print(f\"Using: {DEVICE} with {DTYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File handling with ipywidgets support for local Jupyter\n",
    "\n",
    "class FileUploader:\n",
    "    \"\"\"Cross-platform file uploader that works in Colab and local Jupyter.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.uploaded_file = None\n",
    "    \n",
    "    def upload(self, prompt: str, accept: str = \"\", optional: bool = False) -> Optional[str]:\n",
    "        \"\"\"Upload a file and return the path.\"\"\"\n",
    "        print(prompt)\n",
    "        if optional:\n",
    "            print(\"(Optional - press Enter or Cancel to skip)\")\n",
    "        \n",
    "        if IN_COLAB:\n",
    "            return self._colab_upload(optional)\n",
    "        elif WIDGETS_AVAILABLE:\n",
    "            return self._widget_upload(accept, optional)\n",
    "        else:\n",
    "            return self._text_upload(optional)\n",
    "    \n",
    "    def _colab_upload(self, optional: bool) -> Optional[str]:\n",
    "        \"\"\"Upload using Colab's built-in uploader.\"\"\"\n",
    "        try:\n",
    "            uploaded = files.upload()\n",
    "            if uploaded:\n",
    "                return list(uploaded.keys())[0]\n",
    "        except Exception:\n",
    "            if optional:\n",
    "                return None\n",
    "            raise\n",
    "        return None\n",
    "    \n",
    "    def _widget_upload(self, accept: str, optional: bool) -> Optional[str]:\n",
    "        \"\"\"Upload using ipywidgets FileUpload.\"\"\"\n",
    "        uploader = widgets.FileUpload(accept=accept, multiple=False)\n",
    "        button = widgets.Button(description=\"Confirm Upload\", button_style='success')\n",
    "        skip_button = widgets.Button(description=\"Skip\", button_style='warning') if optional else None\n",
    "        output = widgets.Output()\n",
    "        \n",
    "        self.uploaded_file = None\n",
    "        self._upload_done = False\n",
    "        \n",
    "        def on_confirm(b):\n",
    "            with output:\n",
    "                if uploader.value:\n",
    "                    file_info = list(uploader.value.values())[0]\n",
    "                    filename = list(uploader.value.keys())[0]\n",
    "                    # Save to local file\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(file_info['content'])\n",
    "                    self.uploaded_file = filename\n",
    "                    print(f\"Saved: {filename}\")\n",
    "                else:\n",
    "                    print(\"No file selected\")\n",
    "            self._upload_done = True\n",
    "        \n",
    "        def on_skip(b):\n",
    "            with output:\n",
    "                print(\"Skipped\")\n",
    "            self._upload_done = True\n",
    "        \n",
    "        button.on_click(on_confirm)\n",
    "        if skip_button:\n",
    "            skip_button.on_click(on_skip)\n",
    "            display(widgets.HBox([uploader, button, skip_button]), output)\n",
    "        else:\n",
    "            display(widgets.HBox([uploader, button]), output)\n",
    "        \n",
    "        # Wait for user action\n",
    "        while not self._upload_done:\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        return self.uploaded_file\n",
    "    \n",
    "    def _text_upload(self, optional: bool) -> Optional[str]:\n",
    "        \"\"\"Upload using text input (fallback).\"\"\"\n",
    "        print(\"Enter file path (drag & drop or type):\")\n",
    "        path = input().strip().strip(\"'\\\"\")\n",
    "        if not path:\n",
    "            return None\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "        print(f\"File not found: {path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Global uploader instance\n",
    "uploader = FileUploader()\n",
    "\n",
    "\n",
    "def read_text_file(file_path: str) -> str:\n",
    "    \"\"\"Read text from a file with encoding detection.\"\"\"\n",
    "    for encoding in ['utf-8', 'utf-16', 'latin-1', 'cp1252']:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                return f.read().strip()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Could not decode file: {file_path}\")\n",
    "\n",
    "\n",
    "def download_file(filepath: str):\n",
    "    \"\"\"Download a file.\"\"\"\n",
    "    if IN_COLAB:\n",
    "        files.download(filepath)\n",
    "    else:\n",
    "        print(f\"File saved to: {os.path.abspath(filepath)}\")\n",
    "\n",
    "\n",
    "def play_audio(audio_path: str):\n",
    "    \"\"\"Play audio in the notebook.\"\"\"\n",
    "    display(Audio(audio_path))\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = Path(\"audiobooks\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models\n",
    "\n",
    "Downloads ~6GB on first run (Qwen3-TTS) + ~74MB (Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Whisper model...\")\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "print(\"Whisper loaded!\\n\")\n",
    "\n",
    "print(\"Loading Qwen3-TTS model...\")\n",
    "print(\"(First run downloads ~6GB)\\n\")\n",
    "\n",
    "tts_model = Qwen3TTSModel.from_pretrained(\n",
    "    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\",\n",
    "    device_map=DEVICE,\n",
    "    torch_dtype=DTYPE\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELS READY\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Book Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# EPUB PARSER - Proper reading order and chapter detection\n# ============================================================\n\n@dataclass\nclass Chapter:\n    \"\"\"Represents a chapter with its content and metadata.\"\"\"\n    id: str\n    title: str\n    file_path: str\n    content: str\n\n\nclass EPUBParser:\n    \"\"\"Parse EPUB files using OPF spine for reading order and NCX for chapter titles.\"\"\"\n    \n    # XML Namespaces\n    NS = {\n        'container': 'urn:oasis:names:tc:opendocument:xmlns:container',\n        'opf': 'http://www.idpf.org/2007/opf',\n        'dc': 'http://purl.org/dc/elements/1.1/',\n        'ncx': 'http://www.daisy.org/z3986/2005/ncx/'\n    }\n    \n    def __init__(self, epub_path: str):\n        self.epub_path = epub_path\n        self.opf_path = None\n        self.opf_dir = None\n        self.metadata = {}\n        self.manifest = {}\n        self.spine = []\n        self.ncx_chapters = {}\n        self.cover_path = None\n    \n    def parse(self) -> 'EPUBParser':\n        \"\"\"Parse the EPUB file.\"\"\"\n        with zipfile.ZipFile(self.epub_path, 'r') as z:\n            self._find_opf(z)\n            self._parse_opf(z)\n            self._parse_ncx(z)\n            self._find_cover(z)\n        return self\n    \n    def _find_opf(self, z: zipfile.ZipFile):\n        \"\"\"Find OPF file location from container.xml.\"\"\"\n        container = z.read('META-INF/container.xml').decode('utf-8')\n        root = ET.fromstring(container)\n        rootfile = root.find('.//container:rootfile', self.NS)\n        self.opf_path = rootfile.get('full-path')\n        self.opf_dir = str(Path(self.opf_path).parent)\n    \n    def _parse_opf(self, z: zipfile.ZipFile):\n        \"\"\"Parse OPF for metadata, manifest, and spine.\"\"\"\n        opf_content = z.read(self.opf_path).decode('utf-8')\n        root = ET.fromstring(opf_content)\n        \n        # Metadata\n        metadata = root.find('opf:metadata', self.NS)\n        if metadata is not None:\n            title = metadata.find('dc:title', self.NS)\n            creator = metadata.find('dc:creator', self.NS)\n            self.metadata['title'] = title.text if title is not None else 'Unknown'\n            self.metadata['author'] = creator.text if creator is not None else 'Unknown'\n            \n            # Cover reference\n            for meta in metadata.findall('opf:meta', self.NS):\n                if meta.get('name') == 'cover':\n                    self.metadata['cover_id'] = meta.get('content')\n        \n        # Manifest\n        manifest = root.find('opf:manifest', self.NS)\n        for item in manifest.findall('opf:item', self.NS):\n            item_id = item.get('id')\n            self.manifest[item_id] = {\n                'href': item.get('href'),\n                'media_type': item.get('media-type')\n            }\n        \n        # Spine (reading order)\n        spine = root.find('opf:spine', self.NS)\n        for itemref in spine.findall('opf:itemref', self.NS):\n            idref = itemref.get('idref')\n            linear = itemref.get('linear', 'yes')\n            if linear == 'yes' and idref in self.manifest:\n                media_type = self.manifest[idref]['media_type']\n                if media_type in ('application/xhtml+xml', 'text/html'):\n                    self.spine.append(idref)\n    \n    def _parse_ncx(self, z: zipfile.ZipFile):\n        \"\"\"Parse NCX for chapter titles.\"\"\"\n        # Find NCX file\n        ncx_id = None\n        for item_id, item in self.manifest.items():\n            if item['media_type'] == 'application/x-dtbncx+xml':\n                ncx_id = item_id\n                break\n        \n        if not ncx_id:\n            return\n        \n        ncx_href = self.manifest[ncx_id]['href']\n        ncx_path = f\"{self.opf_dir}/{ncx_href}\" if self.opf_dir else ncx_href\n        \n        try:\n            ncx_content = z.read(ncx_path).decode('utf-8')\n            root = ET.fromstring(ncx_content)\n            \n            for navpoint in root.findall('.//ncx:navPoint', self.NS):\n                label = navpoint.find('ncx:navLabel/ncx:text', self.NS)\n                content = navpoint.find('ncx:content', self.NS)\n                \n                if label is not None and content is not None:\n                    src = content.get('src')\n                    # Remove anchor if present\n                    file_ref = src.split('#')[0] if src else None\n                    title = label.text\n                    \n                    if file_ref and title:\n                        self.ncx_chapters[file_ref] = title\n        except Exception:\n            pass\n    \n    def _find_cover(self, z: zipfile.ZipFile):\n        \"\"\"Find and extract cover image.\"\"\"\n        cover_id = self.metadata.get('cover_id')\n        if cover_id and cover_id in self.manifest:\n            cover_href = self.manifest[cover_id]['href']\n            cover_path = f\"{self.opf_dir}/{cover_href}\" if self.opf_dir else cover_href\n            \n            # Extract cover to temp file\n            try:\n                cover_data = z.read(cover_path)\n                ext = Path(cover_href).suffix\n                temp_cover = f\"/tmp/cover{ext}\"\n                with open(temp_cover, 'wb') as f:\n                    f.write(cover_data)\n                self.cover_path = temp_cover\n            except Exception:\n                pass\n    \n    def get_chapters(self, include_ids: List[str] = None, exclude_ids: List[str] = None) -> List[Chapter]:\n        \"\"\"Get chapters in reading order with optional filtering.\"\"\"\n        chapters = []\n        \n        with zipfile.ZipFile(self.epub_path, 'r') as z:\n            for item_id in self.spine:\n                # Apply filters\n                if include_ids and item_id not in include_ids:\n                    continue\n                if exclude_ids and item_id in exclude_ids:\n                    continue\n                \n                item = self.manifest[item_id]\n                href = item['href']\n                file_path = f\"{self.opf_dir}/{href}\" if self.opf_dir else href\n                \n                # Get title from NCX or use item_id\n                title = self.ncx_chapters.get(href, item_id)\n                \n                # Extract content\n                try:\n                    content = z.read(file_path).decode('utf-8', errors='ignore')\n                    clean_content = clean_html(content)\n                    clean_content = clean_for_tts(clean_content)\n                    \n                    if clean_content.strip():\n                        chapters.append(Chapter(\n                            id=item_id,\n                            title=title,\n                            file_path=file_path,\n                            content=clean_content\n                        ))\n                except Exception:\n                    continue\n        \n        return chapters\n\n\n# ============================================================\n# TEXT CLEANING FOR TTS\n# ============================================================\n\ndef clean_html(html_content: str) -> str:\n    \"\"\"Clean HTML content to plain text.\"\"\"\n    if not html_content:\n        return \"\"\n    if BS4_AVAILABLE:\n        try:\n            soup = BeautifulSoup(html_content, 'html.parser')\n            for script in soup([\"script\", \"style\"]):\n                script.decompose()\n            text = soup.get_text()\n            lines = (line.strip() for line in text.splitlines())\n            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n            return ' '.join(chunk for chunk in chunks if chunk)\n        except Exception:\n            pass\n    # Fallback\n    html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)\n    html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)\n    html_content = re.sub(r'<[^>]+>', ' ', html_content)\n    html_content = unescape(html_content)\n    return re.sub(r'\\s+', ' ', html_content).strip()\n\n\ndef fix_spaced_capitals(text: str) -> str:\n    \"\"\"Convert 'A H OUSE D IVIDED' to 'A House Divided'.\"\"\"\n    # Find sequences of spaced single capitals (3+ in a row)\n    def fix_word(match):\n        chars = match.group(0).replace(' ', '')\n        if len(chars) >= 2:\n            return chars[0] + chars[1:].lower()\n        return chars\n    \n    # Pattern: Capital, space, capital repeated (at least 3 capitals)\n    pattern = r'\\b([A-Z]\\s+){2,}[A-Z]+\\b'\n    return re.sub(pattern, fix_word, text)\n\n\ndef remove_footnote_markers(text: str) -> str:\n    \"\"\"Remove footnote symbols: *, †, ‡, §, etc.\"\"\"\n    # Remove common footnote markers (when not part of a word)\n    markers = r'[*†‡§¶‖¹²³⁴⁵⁶⁷⁸⁹⁰]+'\n    # Remove markers at end of words or standalone\n    text = re.sub(r'\\s*' + markers + r'\\s*', ' ', text)\n    return re.sub(r'\\s+', ' ', text)\n\n\ndef normalize_special_chars(text: str) -> str:\n    \"\"\"Normalize special characters for better TTS.\"\"\"\n    # Em-dash and en-dash to hyphen with spaces\n    text = text.replace('—', ' - ')\n    text = text.replace('–', ' - ')\n    # Curly quotes to straight\n    text = text.replace('\"', '\"').replace('\"', '\"')\n    text = text.replace(''', \"'\").replace(''', \"'\")\n    # Ellipsis\n    text = text.replace('…', '...')\n    return text\n\n\ndef clean_for_tts(text: str, remove_footnotes: bool = True) -> str:\n    \"\"\"Clean text for TTS consumption.\"\"\"\n    # Fix spaced capitals (e.g., \"A H OUSE D IVIDED\")\n    text = fix_spaced_capitals(text)\n    \n    # Remove footnote markers\n    if remove_footnotes:\n        text = remove_footnote_markers(text)\n    \n    # Normalize special characters\n    text = normalize_special_chars(text)\n    \n    # Normalize whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\n\n# ============================================================\n# LEGACY EXTRACTION (for PDF/TXT)\n# ============================================================\n\ndef extract_text_from_epub(file_path: str) -> str:\n    \"\"\"Extract text from EPUB (legacy flat extraction).\"\"\"\n    text_parts = []\n    with zipfile.ZipFile(file_path, 'r') as epub_zip:\n        html_files = sorted([\n            f for f in epub_zip.namelist()\n            if f.lower().endswith(('.html', '.xhtml', '.htm'))\n            and not f.lower().startswith('__macosx')\n        ])\n        for file_name in html_files:\n            try:\n                content = epub_zip.read(file_name).decode('utf-8', errors='ignore')\n                clean_text = clean_html(content)\n                clean_text = clean_for_tts(clean_text)\n                if clean_text.strip():\n                    text_parts.append(clean_text)\n            except Exception:\n                continue\n    return '\\n\\n'.join(text_parts)\n\n\ndef extract_text_from_pdf(file_path: str) -> str:\n    text = \"\"\n    with open(file_path, 'rb') as file:\n        pdf_reader = PyPDF2.PdfReader(file)\n        for page in pdf_reader.pages:\n            try:\n                page_text = page.extract_text()\n                if page_text:\n                    text += f\"\\n\\n{page_text}\"\n            except Exception:\n                continue\n    return clean_for_tts(text.strip())\n\n\ndef extract_text(file_path: str) -> str:\n    ext = Path(file_path).suffix.lower()\n    if ext == '.epub':\n        return extract_text_from_epub(file_path)\n    elif ext == '.pdf':\n        return extract_text_from_pdf(file_path)\n    elif ext == '.txt':\n        return clean_for_tts(read_text_file(file_path))\n    else:\n        raise ValueError(f\"Unsupported format: {ext}\")\n\n\ndef split_into_chunks(text: str, chunk_size_words: int = 1500) -> List[str]:\n    text = re.sub(r'\\s+', ' ', text).strip()\n    sentences = re.split(r'(?<=[.!?])\\s+', text)\n    chunks, current_chunk, current_words = [], \"\", 0\n    for sentence in sentences:\n        sentence_words = len(sentence.split())\n        if current_words + sentence_words <= chunk_size_words:\n            current_chunk += sentence + \" \"\n            current_words += sentence_words\n        else:\n            if current_chunk:\n                chunks.append(current_chunk.strip())\n            current_chunk = sentence + \" \"\n            current_words = sentence_words\n    if current_chunk.strip():\n        chunks.append(current_chunk.strip())\n    return [c for c in chunks if c.strip()]\n\n\nprint(\"Book processing functions loaded!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Audiobook Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# AUDIOBOOK CONVERTER - Chapter-aware with M4B output\n# ============================================================\n\n@dataclass\nclass ChapterAudio:\n    \"\"\"Audio data for a single chapter.\"\"\"\n    id: str\n    title: str\n    audio: np.ndarray\n    sample_rate: int\n    start_time: float = 0.0\n    duration: float = 0.0\n\n\nclass AudiobookConverter:\n    \"\"\"Convert books to audiobooks with chapter markers and M4B output.\"\"\"\n    \n    # Default content to include for EPUBs\n    DEFAULT_INCLUDE = [\n        'foreword', 'introduction',\n        'chapter01', 'chapter02', 'chapter03', 'chapter04', 'chapter05',\n        'chapter06', 'chapter07', 'chapter08', 'chapter09', 'chapter10',\n        'chapter11', 'chapter12', 'chapter13', 'chapter14', 'chapter15',\n    ]\n    \n    # Content to exclude\n    DEFAULT_EXCLUDE = [\n        'frontcoverImage', 'fm01', 'title', 'copyrightPage',\n        'contents', 'mapsandillus', 'acknowledgements',\n        'timeline', 'genealogical', 'transliteration',\n        'maps', 'maps-1', 'maps-2',\n        'further', 'notes', 'bibliography', 'index'\n    ]\n    \n    def __init__(\n        self, \n        tts_model, \n        whisper_model, \n        ref_audio: str, \n        ref_text: Optional[str] = None,\n        config: Optional[Dict] = None\n    ):\n        self.tts_model = tts_model\n        self.whisper_model = whisper_model\n        self.ref_audio = ref_audio\n        self.config = config or {}\n        \n        # Defaults\n        self.announce_chapters = self.config.get('announce_chapters', True)\n        self.chapter_pause = self.config.get('chapter_pause', 2.5)\n        self.chunk_size = self.config.get('chunk_size', 1500)\n        self.output_format = self.config.get('output_format', 'm4b')\n        \n        # Get reference text\n        if ref_text:\n            self.ref_text = ref_text\n            print(f\"Using provided transcript: {self.ref_text[:100]}...\")\n        else:\n            print(\"Transcribing reference audio with Whisper...\")\n            result = self.whisper_model.transcribe(ref_audio)\n            self.ref_text = result[\"text\"].strip()\n            print(f\"Auto-transcription: {self.ref_text}\")\n    \n    def _generate_audio(self, text: str) -> Tuple[np.ndarray, int]:\n        \"\"\"Generate audio using TTS model.\"\"\"\n        wavs, sr = self.tts_model.generate_voice_clone(\n            text=text,\n            language=\"English\",\n            ref_audio=self.ref_audio,\n            ref_text=self.ref_text,\n            x_vector_only_mode=False,\n            non_streaming_mode=True\n        )\n        return wavs[0], sr\n    \n    def _create_silence(self, duration_sec: float, sample_rate: int) -> np.ndarray:\n        \"\"\"Create silence array.\"\"\"\n        return np.zeros(int(duration_sec * sample_rate), dtype=np.float32)\n    \n    def _generate_chapter_audio(self, chapter: Chapter, sample_rate: int = None) -> ChapterAudio:\n        \"\"\"Generate audio for a single chapter with optional announcement.\"\"\"\n        audio_parts = []\n        sr = sample_rate\n        \n        # Generate chapter announcement\n        if self.announce_chapters:\n            print(f\"  Generating announcement: {chapter.title[:50]}...\")\n            try:\n                ann_audio, sr = self._generate_audio(chapter.title)\n                audio_parts.append(ann_audio)\n                # Brief pause after announcement\n                audio_parts.append(self._create_silence(1.0, sr))\n            except Exception as e:\n                print(f\"  Warning: Announcement failed: {e}\")\n        \n        # Generate content in chunks\n        chunks = split_into_chunks(chapter.content, self.chunk_size)\n        print(f\"  Generating {len(chunks)} chunks...\")\n        \n        for i, chunk in enumerate(tqdm(chunks, desc=f\"  {chapter.title[:30]}\", leave=False)):\n            try:\n                audio, sr = self._generate_audio(chunk)\n                audio_parts.append(audio)\n            except Exception as e:\n                print(f\"  Warning: Chunk {i+1} failed: {e}\")\n        \n        # Add pause after chapter\n        if audio_parts:\n            audio_parts.append(self._create_silence(self.chapter_pause, sr))\n        \n        # Concatenate\n        if not audio_parts:\n            raise RuntimeError(f\"No audio generated for chapter: {chapter.title}\")\n        \n        full_audio = np.concatenate(audio_parts)\n        \n        return ChapterAudio(\n            id=chapter.id,\n            title=chapter.title,\n            audio=full_audio,\n            sample_rate=sr,\n            duration=len(full_audio) / sr\n        )\n    \n    def convert_epub(\n        self, \n        epub_path: str,\n        include_ids: List[str] = None,\n        exclude_ids: List[str] = None\n    ) -> str:\n        \"\"\"Convert EPUB to audiobook with chapters.\"\"\"\n        book_name = Path(epub_path).stem\n        \n        # Parse EPUB\n        print(f\"\\nParsing EPUB: {Path(epub_path).name}\")\n        parser = EPUBParser(epub_path).parse()\n        \n        print(f\"Title: {parser.metadata.get('title', 'Unknown')}\")\n        print(f\"Author: {parser.metadata.get('author', 'Unknown')}\")\n        print(f\"Cover: {'Found' if parser.cover_path else 'Not found'}\")\n        \n        # Get chapters with filtering\n        include = include_ids or self.DEFAULT_INCLUDE\n        exclude = exclude_ids or self.DEFAULT_EXCLUDE\n        \n        chapters = parser.get_chapters(include_ids=include, exclude_ids=exclude)\n        \n        if not chapters:\n            # Fall back to getting all content chapters\n            print(\"No chapters matched filters, using all content...\")\n            chapters = parser.get_chapters(exclude_ids=exclude)\n        \n        print(f\"\\nChapters to convert: {len(chapters)}\")\n        for i, ch in enumerate(chapters):\n            word_count = len(ch.content.split())\n            print(f\"  {i+1}. {ch.title} ({word_count:,} words)\")\n        \n        total_words = sum(len(ch.content.split()) for ch in chapters)\n        print(f\"\\nTotal: {total_words:,} words\")\n        \n        # Generate audio for each chapter\n        print(\"\\n\" + \"=\"*50)\n        print(\"GENERATING AUDIO\")\n        print(\"=\"*50)\n        \n        chapter_audios = []\n        current_time = 0.0\n        \n        for i, chapter in enumerate(chapters):\n            print(f\"\\n[{i+1}/{len(chapters)}] {chapter.title}\")\n            \n            try:\n                ch_audio = self._generate_chapter_audio(chapter)\n                ch_audio.start_time = current_time\n                current_time += ch_audio.duration\n                chapter_audios.append(ch_audio)\n                \n                print(f\"  Duration: {ch_audio.duration/60:.1f} minutes\")\n            except Exception as e:\n                print(f\"  ERROR: {e}\")\n        \n        if not chapter_audios:\n            raise RuntimeError(\"No audio generated\")\n        \n        # Save output\n        print(\"\\n\" + \"=\"*50)\n        print(\"SAVING OUTPUT\")\n        print(\"=\"*50)\n        \n        output_path = self._save_audiobook(\n            chapter_audios,\n            book_name,\n            parser.metadata,\n            parser.cover_path\n        )\n        \n        total_duration = sum(ca.duration for ca in chapter_audios)\n        print(f\"\\nTotal duration: {total_duration/60:.1f} minutes\")\n        print(f\"Output: {output_path}\")\n        \n        return output_path\n    \n    def _save_audiobook(\n        self,\n        chapter_audios: List[ChapterAudio],\n        book_name: str,\n        metadata: Dict,\n        cover_path: str = None\n    ) -> str:\n        \"\"\"Save audiobook with chapter markers.\"\"\"\n        \n        # Concatenate all audio\n        all_audio = np.concatenate([ca.audio for ca in chapter_audios])\n        sample_rate = chapter_audios[0].sample_rate\n        \n        # Save as WAV first\n        wav_path = str(OUTPUT_DIR / f\"{book_name}_temp.wav\")\n        sf.write(wav_path, all_audio, sample_rate)\n        \n        if self.output_format == 'wav':\n            output_path = str(OUTPUT_DIR / f\"{book_name}.wav\")\n            os.rename(wav_path, output_path)\n            return output_path\n        \n        # Create M4B with chapters\n        output_path = str(OUTPUT_DIR / f\"{book_name}.m4b\")\n        \n        try:\n            # Create metadata file\n            metadata_path = self._create_ffmetadata(chapter_audios, metadata)\n            \n            # Build ffmpeg command\n            cmd = [\n                \"ffmpeg\", \"-y\",\n                \"-i\", wav_path,\n                \"-i\", metadata_path,\n                \"-map\", \"0:a\",\n                \"-map_metadata\", \"1\",\n                \"-c:a\", \"aac\",\n                \"-b:a\", \"128k\",\n            ]\n            \n            # Add cover if available\n            if cover_path and os.path.exists(cover_path):\n                cmd.extend([\n                    \"-i\", cover_path,\n                    \"-map\", \"2:v\",\n                    \"-c:v\", \"mjpeg\",\n                    \"-disposition:v:0\", \"attached_pic\"\n                ])\n            \n            cmd.append(output_path)\n            \n            print(\"Creating M4B with chapter markers...\")\n            result = subprocess.run(cmd, capture_output=True, text=True)\n            \n            if result.returncode != 0:\n                print(f\"FFmpeg warning: {result.stderr[:500] if result.stderr else 'Unknown'}\")\n                # Fall back to WAV\n                output_path = str(OUTPUT_DIR / f\"{book_name}.wav\")\n                os.rename(wav_path, output_path)\n                print(f\"Saved as WAV instead: {output_path}\")\n            else:\n                # Clean up\n                os.remove(wav_path)\n                os.remove(metadata_path)\n                print(f\"M4B created with {len(chapter_audios)} chapters\")\n        \n        except FileNotFoundError:\n            print(\"FFmpeg not found - saving as WAV\")\n            output_path = str(OUTPUT_DIR / f\"{book_name}.wav\")\n            os.rename(wav_path, output_path)\n        \n        return output_path\n    \n    def _create_ffmetadata(self, chapter_audios: List[ChapterAudio], metadata: Dict) -> str:\n        \"\"\"Create FFMETADATA file for chapter markers.\"\"\"\n        lines = [\";FFMETADATA1\"]\n        lines.append(f\"title={metadata.get('title', 'Audiobook')}\")\n        lines.append(f\"artist={metadata.get('author', 'Unknown')}\")\n        lines.append(f\"album={metadata.get('title', 'Audiobook')}\")\n        lines.append(\"\")\n        \n        for ca in chapter_audios:\n            start_ms = int(ca.start_time * 1000)\n            end_ms = int((ca.start_time + ca.duration) * 1000)\n            \n            lines.append(\"[CHAPTER]\")\n            lines.append(\"TIMEBASE=1/1000\")\n            lines.append(f\"START={start_ms}\")\n            lines.append(f\"END={end_ms}\")\n            lines.append(f\"title={ca.title}\")\n            lines.append(\"\")\n        \n        metadata_path = str(OUTPUT_DIR / \"ffmetadata.txt\")\n        with open(metadata_path, 'w', encoding='utf-8') as f:\n            f.write('\\n'.join(lines))\n        \n        return metadata_path\n    \n    # Legacy method for non-EPUB files\n    def convert(self, book_path: str, chunk_size_words: int = 1500) -> str:\n        \"\"\"Convert PDF/TXT to audiobook (legacy flat conversion).\"\"\"\n        ext = Path(book_path).suffix.lower()\n        \n        if ext == '.epub':\n            return self.convert_epub(book_path)\n        \n        book_name = Path(book_path).stem\n        output_path = str(OUTPUT_DIR / f\"{book_name}.wav\")\n        \n        print(f\"\\nExtracting text from {Path(book_path).name}...\")\n        text = extract_text(book_path)\n        word_count = len(text.split())\n        print(f\"Extracted {word_count:,} words\")\n        \n        chunks = split_into_chunks(text, chunk_size_words)\n        print(f\"Split into {len(chunks)} chunks\\n\")\n        \n        audio_segments = []\n        sample_rate = None\n        \n        for i, chunk in enumerate(tqdm(chunks, desc=\"Generating audio\")):\n            try:\n                audio, sr = self._generate_audio(chunk)\n                audio_segments.append(audio)\n                sample_rate = sr\n            except Exception as e:\n                print(f\"\\nWarning: Chunk {i+1} failed: {e}\")\n        \n        if not audio_segments:\n            raise RuntimeError(\"No audio generated\")\n        \n        print(f\"\\nCombining {len(audio_segments)} segments...\")\n        combined = np.concatenate(audio_segments)\n        sf.write(output_path, combined, sample_rate)\n        \n        duration_min = len(combined) / sample_rate / 60\n        print(f\"\\nSaved: {output_path}\")\n        print(f\"Duration: {duration_min:.1f} minutes\")\n        \n        return output_path\n\n\nprint(\"AudiobookConverter ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Convert EPUB to Voice-Cloned Audiobook\n\n**Features:**\n- Chapter-aware extraction with proper reading order (OPF spine)\n- Chapter titles from NCX navigation\n- Clean text processing (removes footnotes, fixes formatting)\n- M4B output with embedded chapter markers\n- Cover art embedding (from EPUB)\n- Configurable content inclusion/exclusion\n\n**Upload your files:**\n1. **Voice sample** (WAV/MP3/FLAC) - 5-30 seconds of clear speech\n2. **Transcript** (optional .txt) - exact words in the voice sample\n3. **Book file** (EPUB recommended, also PDF/TXT)\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Upload voice sample\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 1: VOICE SAMPLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "voice_audio_path = uploader.upload(\n",
    "    \"Upload your voice sample (WAV, MP3, or FLAC):\",\n",
    "    accept=\".wav,.mp3,.flac\"\n",
    ")\n",
    "\n",
    "if voice_audio_path:\n",
    "    print(f\"\\nVoice sample: {voice_audio_path}\")\n",
    "    print(\"\\nPreview:\")\n",
    "    play_audio(voice_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Upload transcript (optional)\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 2: TRANSCRIPT (OPTIONAL)\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nProviding a transcript improves voice cloning quality.\")\n",
    "print(\"If skipped, Whisper will auto-transcribe.\\n\")\n",
    "\n",
    "transcript_text = None\n",
    "transcript_path = uploader.upload(\n",
    "    \"Upload transcript file (.txt):\",\n",
    "    accept=\".txt\",\n",
    "    optional=True\n",
    ")\n",
    "\n",
    "if transcript_path:\n",
    "    transcript_text = read_text_file(transcript_path)\n",
    "    print(f\"\\nTranscript loaded: {transcript_text}\")\n",
    "else:\n",
    "    print(\"\\nNo transcript provided - will auto-transcribe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Upload book\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 3: BOOK FILE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "book_path = uploader.upload(\n",
    "    \"Upload your book (EPUB, PDF, or TXT):\",\n",
    "    accept=\".epub,.pdf,.txt\"\n",
    ")\n",
    "\n",
    "if book_path:\n",
    "    print(f\"\\nBook: {book_path}\")\n",
    "    print(f\"Format: {Path(book_path).suffix.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 4: Configure and Convert!\nif voice_audio_path and book_path:\n    print(\"=\"*50)\n    print(\"CONFIGURATION\")\n    print(\"=\"*50)\n    \n    # ============================================================\n    # CONVERSION SETTINGS - Modify these as needed\n    # ============================================================\n    \n    config = {\n        # Chapter announcements (TTS reads chapter title before content)\n        'announce_chapters': True,\n        \n        # Pause duration between chapters (seconds)\n        'chapter_pause': 2.5,\n        \n        # Words per TTS chunk (larger = fewer API calls, smaller = better for long content)\n        'chunk_size': 1500,\n        \n        # Output format: 'm4b' (with chapters) or 'wav' (lossless)\n        'output_format': 'm4b',\n    }\n    \n    # Content to INCLUDE (for EPUBs) - set to None to use defaults\n    # Default includes: foreword, introduction, chapter01-15\n    include_content = None  # Or specify: ['foreword', 'introduction', 'chapter01', ...]\n    \n    # Content to EXCLUDE (for EPUBs) - set to None to use defaults\n    # Default excludes: TOC, copyright, notes, index, maps, etc.\n    exclude_content = None  # Or specify: ['notes', 'index', 'bibliography', ...]\n    \n    # ============================================================\n    \n    print(f\"Announce chapters: {config['announce_chapters']}\")\n    print(f\"Chapter pause: {config['chapter_pause']}s\")\n    print(f\"Output format: {config['output_format'].upper()}\")\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"CONVERTING TO AUDIOBOOK\")\n    print(\"=\"*50)\n    \n    converter = AudiobookConverter(\n        tts_model=tts_model,\n        whisper_model=whisper_model,\n        ref_audio=voice_audio_path,\n        ref_text=transcript_text,\n        config=config\n    )\n    \n    # Use appropriate conversion method\n    ext = Path(book_path).suffix.lower()\n    if ext == '.epub':\n        output_file = converter.convert_epub(\n            book_path,\n            include_ids=include_content,\n            exclude_ids=exclude_content\n        )\n    else:\n        output_file = converter.convert(book_path)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"DONE!\")\n    print(\"=\"*50)\n    print(\"\\nPreview (first 30 seconds):\")\n    play_audio(output_file)\nelse:\n    print(\"Please complete Steps 1 and 3 above first.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Download\nif 'output_file' in dir() and output_file and os.path.exists(output_file):\n    file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n    print(f\"Output file: {output_file}\")\n    print(f\"File size: {file_size_mb:.1f} MB\")\n    \n    if output_file.endswith('.m4b'):\n        print(\"\\nM4B files can be played in:\")\n        print(\"  - Apple Books / iTunes\")\n        print(\"  - VLC Media Player\")\n        print(\"  - Most podcast/audiobook apps\")\n        print(\"  - Supports chapter navigation!\")\n    \n    print(f\"\\nDownloading: {Path(output_file).name}\")\n    download_file(output_file)\nelse:\n    print(\"Run Step 4 first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Memory cleared\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}